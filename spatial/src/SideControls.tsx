// Copyright 2024 Google LLC

// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at

//     https://www.apache.org/licenses/LICENSE-2.0

// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import { useAtom } from "jotai";
import {
  ImageSrcAtom,
  ImageSentAtom,
  DrawModeAtom,
  IsUploadedImageAtom,
  BumpSessionAtom,
  IsAnnotatingAtom,
  DetectTypeAtom,
  BoundingBoxes2DAtom,
  AnnotatedImagesAtom,
} from "./atoms";
import { ScreenshareButton } from "./ScreenshareButton";
import { useResetState } from "./hooks";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { loadImage } from "./utils";

export function SideControls() {
  const [imageSrc, setImageSrc] = useAtom(ImageSrcAtom);
  const [drawMode, setDrawMode] = useAtom(DrawModeAtom);
  const [, setIsUploadedImage] = useAtom(IsUploadedImageAtom);
  const [, setBumpSession] = useAtom(BumpSessionAtom);
  const [, setImageSent] = useAtom(ImageSentAtom);
  const [isAnnotating, setIsAnnotating] = useAtom(IsAnnotatingAtom);
  const [, setBoundingBoxes2D] = useAtom(BoundingBoxes2DAtom);
  const [annotatedImages, setAnnotatedImages] = useAtom(AnnotatedImagesAtom);
  const resetState = useResetState();

  // æ‰§è¡Œæ ‡æ³¨çš„å‡½æ•°
  const performAnnotation = async (imageDataUrl: string) => {
    console.log("[è‡ªåŠ¨æ ‡æ³¨] å¼€å§‹æ‰§è¡Œæ ‡æ³¨æµç¨‹");
    try {
      // å‡†å¤‡å›¾åƒæ•°æ®
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å¼€å§‹å‡†å¤‡å›¾åƒæ•°æ®");
      const maxSize = 640;
      const copyCanvas = document.createElement("canvas");
      const ctx = copyCanvas.getContext("2d")!;
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] åŠ è½½å›¾åƒ");
      const image = await loadImage(imageDataUrl);
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å›¾åƒåŠ è½½å®Œæˆï¼ŒåŸå§‹å°ºå¯¸:", image.width, "x", image.height);
      
      const scale = Math.min(maxSize / image.width, maxSize / image.height);
      copyCanvas.width = image.width * scale;
      copyCanvas.height = image.height * scale;
      console.log("[è‡ªåŠ¨æ ‡æ³¨] è°ƒæ•´å›¾åƒå°ºå¯¸ä¸º:", copyCanvas.width, "x", copyCanvas.height, "ç¼©æ”¾æ¯”ä¾‹:", scale);
      
      ctx.drawImage(image, 0, 0, image.width * scale, image.height * scale);
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å›¾åƒç»˜åˆ¶åˆ°Canvaså®Œæˆ");
      
      const processedDataURL = copyCanvas.toDataURL("image/png");
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å›¾åƒè½¬æ¢ä¸ºDataURLå®Œæˆ");
      
      // æ„å»ºæç¤ºè¯
      const prompt = `Detect only å»ºç­‘ç‰© in the image, ignoring reflections in water, shadows, or other non-building elements. Focus on the main structures and architectural elements. Limit to no more than 10 clear buildings. Output a json list where each entry contains the 2D bounding box in "box_2d" and a text label in "label".`;
      console.log("[è‡ªåŠ¨æ ‡æ³¨] æç¤ºè¯å‡†å¤‡å®Œæˆ");
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å¼€å§‹è°ƒç”¨Gemini API");
      // åˆ›å»ºAPIå®¢æˆ·ç«¯
      const client = new GoogleGenerativeAI(import.meta.env.VITE_GEMINI_API_KEY);
      console.log("[è‡ªåŠ¨æ ‡æ³¨] APIå®¢æˆ·ç«¯åˆ›å»ºå®Œæˆ");
      
      // å‘é€è¯·æ±‚
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å‘é€å›¾åƒè¯†åˆ«è¯·æ±‚");
      let response = (await client
        .getGenerativeModel(
          {model: "models/gemini-1.5-flash"},
          {apiVersion: 'v1beta'}
        )
        .generateContent({
          contents: [
            {
              role: "user",
              parts: [
                {text: prompt},
                {inlineData: {
                  data: processedDataURL.replace("data:image/png;base64,", ""),
                  mimeType: "image/png"
                }}
              ]
            }
          ],
          generationConfig: {temperature: 0.5}
        })).response.text();
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] æ”¶åˆ°APIå“åº”");
      // å¤„ç†å“åº”
      if (response.includes("```json")) {
        console.log("[è‡ªåŠ¨æ ‡æ³¨] å“åº”åŒ…å«JSONä»£ç å—ï¼Œæå–JSONå†…å®¹");
        response = response.split("```json")[1].split("```")[0];
      }
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] è§£æJSONå“åº”");
      const parsedResponse = JSON.parse(response);
      console.log(`[è‡ªåŠ¨æ ‡æ³¨] æ£€æµ‹åˆ° ${parsedResponse.length} ä¸ªå»ºç­‘ç‰©`);
      
      const formattedBoxes = parsedResponse.map(
        (box: { box_2d: [number, number, number, number]; label: string }, index: number) => {
          const [ymin, xmin, ymax, xmax] = box.box_2d;
          console.log(`[è‡ªåŠ¨æ ‡æ³¨] å¤„ç†ç¬¬ ${index+1} ä¸ªå»ºç­‘ç‰©: ${box.label}, åæ ‡: [${xmin/1000}, ${ymin/1000}, ${xmax/1000}, ${ymax/1000}]`);
          return {
            x: xmin / 1000,
            y: ymin / 1000,
            width: (xmax - xmin) / 1000,
            height: (ymax - ymin) / 1000,
            label: box.label,
          };
        },
      );
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] å¼€å§‹æ›´æ–°åº”ç”¨çŠ¶æ€");
      // æ›´æ–°çŠ¶æ€
      console.log("[è‡ªåŠ¨æ ‡æ³¨] è®¾ç½®è¾¹ç•Œæ¡†æ•°æ®");
      setBoundingBoxes2D(formattedBoxes);
      
      // ä¿å­˜æ ‡æ³¨å›¾ç‰‡
      const imageId = Date.now().toString();
      const timestamp = Date.now();
      console.log(`[è‡ªåŠ¨æ ‡æ³¨] åˆ›å»ºæ–°çš„æ ‡æ³¨å›¾ç‰‡è®°å½•, ID: ${imageId}, æ—¶é—´æˆ³: ${new Date(timestamp).toLocaleString()}`);
      
      const newAnnotatedImage = {
        id: imageId,
        src: processedDataURL,
        timestamp: timestamp,
        type: "2D bounding boxes" as const,
        annotations: formattedBoxes
      };
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] ä¿å­˜æ ‡æ³¨å›¾ç‰‡åˆ°åˆ—è¡¨");
      setAnnotatedImages((prev) => {
        console.log(`[è‡ªåŠ¨æ ‡æ³¨] æ›´æ–°æ ‡æ³¨å›¾ç‰‡åˆ—è¡¨ï¼Œå½“å‰åˆ—è¡¨é•¿åº¦: ${prev.length}, æ–°é•¿åº¦: ${prev.length + 1}`);
        return [newAnnotatedImage, ...prev];
      });
      
      console.log("[è‡ªåŠ¨æ ‡æ³¨] è®¾ç½®å›¾åƒå·²å‘é€çŠ¶æ€");
      setImageSent(true);
      console.log("[è‡ªåŠ¨æ ‡æ³¨] æ ‡æ³¨æµç¨‹å®Œæˆ");
    } catch (error) {
      console.error("[è‡ªåŠ¨æ ‡æ³¨] æ ‡æ³¨è¿‡ç¨‹å¤±è´¥:", error);
    } finally {
      console.log("[è‡ªåŠ¨æ ‡æ³¨] é‡ç½®æ ‡æ³¨çŠ¶æ€ä¸ºå®Œæˆ");
      setIsAnnotating(false);
    }
  };

  return (
    <div className="flex flex-col gap-3">
      <label className={`flex items-center button bg-[#3B68FF] px-12 !text-white !border-none ${isAnnotating ? 'opacity-50 cursor-not-allowed' : ''}`}>
        <input
          className="hidden"
          type="file"
          accept=".jpg, .jpeg, .png, .webp"
          disabled={isAnnotating}
          onChange={(e) => {
            const file = e.target.files?.[0];
            if (file) {
              console.log(`[ä¸Šä¼ å›¾ç‰‡] å¼€å§‹å¤„ç†æ–‡ä»¶: ${file.name}, å¤§å°: ${(file.size / 1024).toFixed(2)}KB, ç±»å‹: ${file.type}`);
              
              // å…ˆè®¾ç½®æ ‡æ³¨çŠ¶æ€
              setIsAnnotating(true);
              console.log("[ä¸Šä¼ å›¾ç‰‡] è®¾ç½®æ ‡æ³¨çŠ¶æ€ä¸ºè¿›è¡Œä¸­");
              
              const reader = new FileReader();
              reader.onload = async (e) => {
                try {
                  console.log("[ä¸Šä¼ å›¾ç‰‡] æ–‡ä»¶è¯»å–å®Œæˆï¼Œå‡†å¤‡å¤„ç†å›¾åƒæ•°æ®");
                  const imageDataUrl = e.target?.result as string;
                  
                  // é‡ç½®çŠ¶æ€å¹¶è®¾ç½®æ–°å›¾åƒ
                  console.log("[ä¸Šä¼ å›¾ç‰‡] é‡ç½®åº”ç”¨çŠ¶æ€");
                  resetState();
                  console.log("[ä¸Šä¼ å›¾ç‰‡] è®¾ç½®å›¾åƒæº");
                  setImageSrc(imageDataUrl);
                  console.log("[ä¸Šä¼ å›¾ç‰‡] æ ‡è®°ä¸ºä¸Šä¼ å›¾åƒ");
                  setIsUploadedImage(true);
                  console.log("[ä¸Šä¼ å›¾ç‰‡] é‡ç½®å›¾åƒå‘é€çŠ¶æ€");
                  setImageSent(false);
                  console.log("[ä¸Šä¼ å›¾ç‰‡] æ›´æ–°ä¼šè¯ID");
                  setBumpSession((prev) => prev + 1);
                  
                  // ç¡®ä¿å›¾åƒå·²åŠ è½½
                  console.log("[ä¸Šä¼ å›¾ç‰‡] ç­‰å¾…å›¾åƒå®Œå…¨åŠ è½½");
                  const image = new Image();
                  image.src = imageDataUrl;
                  
                  await new Promise((resolve) => {
                    image.onload = resolve;
                  });
                  
                  console.log("[ä¸Šä¼ å›¾ç‰‡] å›¾åƒåŠ è½½å®Œæˆï¼Œå°ºå¯¸:", image.width, "x", image.height);
                  console.log("[ä¸Šä¼ å›¾ç‰‡] å¼€å§‹æ‰§è¡Œè‡ªåŠ¨æ ‡æ³¨");
                  
                  // ç›´æ¥ä½¿ç”¨è¯»å–åˆ°çš„å›¾åƒæ•°æ®è¿›è¡Œæ ‡æ³¨
                  await performAnnotation(imageDataUrl);
                } catch (error) {
                  console.error("[ä¸Šä¼ å›¾ç‰‡] å¤„ç†å›¾åƒå¤±è´¥:", error);
                  setIsAnnotating(false);
                }
              };
              
              reader.onerror = () => {
                console.error("[ä¸Šä¼ å›¾ç‰‡] è¯»å–æ–‡ä»¶å¤±è´¥");
                setIsAnnotating(false);
              };
              
              console.log("[ä¸Šä¼ å›¾ç‰‡] å¼€å§‹è¯»å–æ–‡ä»¶æ•°æ®");
              reader.readAsDataURL(file);
            }
          }}
        />
        <div>{isAnnotating ? "è‡ªåŠ¨æ ‡æ³¨ä¸­..." : "ä¸Šä¼ å›¾ç‰‡"}</div>
      </label>
      <div className="hidden">
        <button
          className="button flex gap-3 justify-center items-center"
          onClick={() => {
            setDrawMode(!drawMode);
          }}
        >
          <div className="text-lg"> ğŸ¨</div>
          <div>Draw on image</div>
        </button>
        <ScreenshareButton />
      </div>
    </div>
  );
}
